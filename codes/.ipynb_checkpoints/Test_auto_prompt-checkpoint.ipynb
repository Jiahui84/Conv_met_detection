{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result has been written to gpt_output.csv\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 替换成你的API密钥\n",
    "openai.api_key = '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'\n",
    "\n",
    "# 要发送给GPT的prompt\n",
    "query = \"\"\"If I want to prompt ChatGPT to do conventional metaphor detection. What kind of prompt do you think will be efficient? Can you give my 5 different prompts? \n",
    "The workflow for the task:\n",
    "1) ChatGPT will be given examples for learning, specify the place for examples in the prompts. \n",
    "2) Then ChatGPT will be given an input sentence, and output every word in the sentence, one word per row. The conventional metaphorical word will be appended \":1\".\n",
    "\"\"\"\n",
    "\n",
    "# 创建GPT-4聊天模型完成请求\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-1106-preview\",  # 指定模型\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],  # 按照要求提供messages\n",
    "    temperature=0.7,  # 温度设置为0，以获取更确定性的响应\n",
    "    max_tokens=2000  # 响应的最大长度\n",
    ")\n",
    "\n",
    "# 获取生成的文本\n",
    "generated_text = response['choices'][0]['message']['content'] if response['choices'] else 'No response'\n",
    "\n",
    "\n",
    "# 将结果写入CSV文件\n",
    "with open('C:/Users/TImaze/Desktop/ChatGPT_conv_met/Test_auto_prompt/output.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Generated Text'])\n",
    "    writer.writerow([generated_text])\n",
    "\n",
    "print(\"The result has been written to gpt_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result has been written to gpt_output.txt\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 替换成你的API密钥\n",
    "openai.api_key = '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'\n",
    "\n",
    "# 要发送给GPT的prompt\n",
    "query = \"\"\"If I want to prompt ChatGPT to do conventional metaphor detection. What kind of prompt do you think will be efficient? Can you give my 5 different prompts? In each prompt the task is organized in steps. \n",
    "The workflow for the task:\n",
    "1) ChatGPT will be given labelled examples for learning\n",
    "2) Then ChatGPT will be given an input sentence, and output every word in the sentence, one word per row. The conventional metaphorical word will be appended \":1\".\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 创建GPT-4聊天模型完成请求\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-1106-preview\",  # 指定模型\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],  # 按照要求提供messages\n",
    "    temperature=0.7,  # 温度设置为0，以获取更确定性的响应\n",
    "    max_tokens=2000  # 响应的最大长度\n",
    ")\n",
    "\n",
    "# 获取生成的文本\n",
    "generated_text = response['choices'][0]['message']['content'] if response['choices'] else 'No response'\n",
    "\n",
    "# 将结果写入TXT文件\n",
    "with open('C:/Users/TImaze/Desktop/ChatGPT_conv_met/Test_auto_prompt/output_steps.txt', 'w', encoding='utf-8') as textfile:\n",
    "    textfile.write(generated_text)\n",
    "\n",
    "print(\"The result has been written to gpt_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result has been written to gpt_output.txt\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 替换成你的API密钥\n",
    "openai.api_key = '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'\n",
    "\n",
    "# 要发送给GPT的prompt\n",
    "query = \"\"\"If I want to prompt ChatGPT to do conventional metaphor detection. What kind of prompt do you think will be efficient? Can you give my 5 different prompts for this task and involve background information such as the definition of conventional metaphor in the prompts? \n",
    "The workflow for the task:\n",
    "1) ChatGPT will be given labelled examples for learning\n",
    "2) Then ChatGPT will be given an input sentence, and output every word in the sentence, one word per row. The conventional metaphorical word will be appended \":1\".\n",
    "\"\"\"\n",
    "\n",
    "# 创建GPT-4聊天模型完成请求\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-1106-preview\",  # 指定模型\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],  # 按照要求提供messages\n",
    "    temperature=0.7,  # 温度设置为0，以获取更确定性的响应\n",
    "    max_tokens=2000  # 响应的最大长度\n",
    ")\n",
    "\n",
    "# 获取生成的文本\n",
    "generated_text = response['choices'][0]['message']['content'] if response['choices'] else 'No response'\n",
    "\n",
    "# 将结果写入TXT文件\n",
    "with open('C:/Users/TImaze/Desktop/ChatGPT_conv_met/Test_auto_prompt/output_background.txt', 'w', encoding='utf-8') as textfile:\n",
    "    textfile.write(generated_text)\n",
    "\n",
    "print(\"The result has been written to gpt_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result has been written to gpt_output.txt\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 替换成你的API密钥\n",
    "openai.api_key = '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'\n",
    "\n",
    "# 要发送给GPT的prompt\n",
    "query = \"\"\"If I want to prompt ChatGPT to do conventional metaphor detection. What kind of prompt do you think will be efficient? Can you give my 5 different prompts of different length and styles? \n",
    "The workflow for the task:\n",
    "1) ChatGPT will be given labelled examples for learning\n",
    "2) Then ChatGPT will be given an input sentence, and output every word in the sentence, one word per row. The conventional metaphorical word will be appended \":1\".\n",
    "\"\"\"\n",
    "\n",
    "# 创建GPT-4聊天模型完成请求\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-1106-preview\",  # 指定模型\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],  # 按照要求提供messages\n",
    "    temperature=0.7,  # 温度设置为0，以获取更确定性的响应\n",
    "    max_tokens=2000  # 响应的最大长度\n",
    ")\n",
    "\n",
    "# 获取生成的文本\n",
    "generated_text = response['choices'][0]['message']['content'] if response['choices'] else 'No response'\n",
    "\n",
    "# 将结果写入TXT文件\n",
    "with open('C:/Users/TImaze/Desktop/ChatGPT_conv_met/Test_auto_prompt/output_different.txt', 'w', encoding='utf-8') as textfile:\n",
    "    textfile.write(generated_text)\n",
    "\n",
    "print(\"The result has been written to gpt_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result has been written to gpt_output.txt\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "# 替换成你的API密钥\n",
    "openai.api_key = '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'\n",
    "\n",
    "# 要发送给GPT的prompt\n",
    "query = \"\"\"Here is the manual conventional metaphor identification procedure:\n",
    "1. Read the entire text–discourse to establish a general understanding of the meaning.\n",
    "2. Determine the lexical units in the text–discourse\n",
    "3. (a) For each lexical unit in the text, establish its meaning in context, that is, how it applies to an entity, relation, or attribute in the situation evoked by the text (contextual meaning). Take into account what comes before and after the lexical unit.\n",
    "(b) For each lexical unit, determine if its contextual meaning has been lexicalized and written into dictionary.\n",
    "(c) For each lexical unit, determine if it has a more basic contemporary meaning in other contexts than the one in the given context.\n",
    "(d) If the lexical unit has a more basic current–contemporary meaning in other contexts than the given context, decide whether the contextual meaning contrasts with the basic meaning but can be understood in comparison with it.\n",
    "4. If yes, mark the lexical unit as metaphorical.\n",
    "Develop five prompts based on the conventional metaphor identification procedure that can be used to instruct an AI to detect conventional metaphors within a text. Each prompt should correspond to a step in the procedure, ensuring the AI can identify metaphorical words by contrasting their contextual meaning with their basic contemporary meaning. The prompts should be designed to guide the AI through (1) reading for comprehension, (2) identifying lexical units, (3) analyzing context and dictionary meanings, (4) contrasting meanings, and (5) marking metaphorical usage with ':1'.\n",
    "\"\"\"\n",
    "\n",
    "# 创建GPT-4聊天模型完成请求\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4-1106-preview\",  # 指定模型\n",
    "    messages=[{\"role\": \"user\", \"content\": query}],  # 按照要求提供messages\n",
    "    temperature=0.7,  # 温度设置为0，以获取更确定性的响应\n",
    "    max_tokens=2000  # 响应的最大长度\n",
    ")\n",
    "\n",
    "# 获取生成的文本\n",
    "generated_text = response['choices'][0]['message']['content'] if response['choices'] else 'No response'\n",
    "\n",
    "# 将结果写入TXT文件\n",
    "with open('C:/Users/TImaze/Desktop/ChatGPT_conv_met/Test_auto_prompt/output_MIP.txt', 'w', encoding='utf-8') as textfile:\n",
    "    textfile.write(generated_text)\n",
    "\n",
    "print(\"The result has been written to gpt_output.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
